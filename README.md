# ğŸ›¡ï¸ VoiceShield AI

> **Real-time voice-powered emergency detection and response system using AI**

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![ElevenLabs](https://img.shields.io/badge/ElevenLabs-Voice_AI-blue)](https://elevenlabs.io)
[![Google Gemini](https://img.shields.io/badge/Google-Gemini_AI-orange)](https://ai.google.dev)

VoiceShield is an intelligent emergency response assistant that listens to voice input, detects emergency situations in real-time, classifies them by type and severity, and provides immediate AI-generated guidance with voice responses.

![VoiceShield Demo](https://via.placeholder.com/800x400?text=VoiceShield+AI+Demo)

## âœ¨ Features

- ğŸ™ï¸ **Real-time Voice Recording** - Browser-based microphone input
- ğŸ”Š **Speech-to-Text** - ElevenLabs Scribe V2 for accurate transcription
- ğŸ§  **AI Emergency Classification** - Detects Fire, Medical, Violence, Accident emergencies
- ğŸ¤– **Intelligent Response** - Google Gemini AI generates contextual emergency guidance
- ğŸ”ˆ **Text-to-Speech** - ElevenLabs voices deliver natural audio responses
- ğŸ“¡ **Real-time Updates** - WebSocket-powered live event feed
- ğŸ’¾ **Persistent Storage** - MongoDB Atlas for event history

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend â”‚â—€â”€â”€â”€â”€â”€â”€â–¶â”‚  FastAPI Backend â”‚â—€â”€â”€â”€â”€â”€â”€â–¶â”‚  MongoDB Atlas  â”‚
â”‚   (Voice UI)     â”‚   WS   â”‚   (Processing)   â”‚        â”‚   (Storage)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼               â–¼               â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ ElevenLabs  â”‚ â”‚   Gemini    â”‚ â”‚ ElevenLabs  â”‚
            â”‚    STT      â”‚ â”‚     AI      â”‚ â”‚    TTS      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- MongoDB Atlas account
- ElevenLabs API key
- Google Gemini API key

### Backend Setup

```bash
cd backend

# Install dependencies
pip install -r requirements.txt

# Create .env file
cat > .env << EOF
MONGO_URL=your_mongodb_connection_string
DB_NAME=voice_assistant_db
CORS_ORIGINS=*
EOF

# Run server
uvicorn server:app --host 0.0.0.0 --port 8000 --reload
```

### Frontend Setup

```bash
cd frontend

# Install dependencies
yarn install

# Create .env file
echo "REACT_APP_BACKEND_URL=http://localhost:8000" > .env

# Run development server
yarn start
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸ¯ How It Works

1. **User speaks** into the microphone
2. **ElevenLabs STT** transcribes speech to text
3. **Keyword classifier** detects emergency type:
   - ğŸ”¥ **FIRE** - fire, smoke, burning, flames
   - ğŸ¥ **MEDICAL** - hurt, injured, pain, unconscious
   - âš ï¸ **VIOLENCE** - attack, threat, weapon, danger
   - ğŸš— **ACCIDENT** - crash, collision, vehicle
   - âœ… **NORMAL** - no emergency detected
4. **Gemini AI** generates appropriate emergency response
5. **ElevenLabs TTS** converts response to speech
6. **WebSocket** broadcasts event to all connected clients

## ğŸ“ Project Structure

```
voiceshield/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.py              # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ voice.py           # Voice processing endpoints
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ complete_flow.py   # Main processing pipeline
â”‚   â”‚   â”œâ”€â”€ elevenlabs_stt.py  # Speech-to-text service
â”‚   â”‚   â”œâ”€â”€ elevenlabs_tts.py  # Text-to-speech service
â”‚   â”‚   â”œâ”€â”€ gemini_response.py # AI response generation
â”‚   â”‚   â””â”€â”€ event_store.py     # MongoDB operations
â”‚   â””â”€â”€ websocket/
â”‚       â””â”€â”€ ws_manager.py      # WebSocket management
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ pages/             # Page components
â”‚   â”‚   â””â”€â”€ services/          # API services
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/voice` | Process voice recording |
| `GET` | `/api/events` | Get recent events |
| `GET` | `/api/audio/{id}` | Get audio response |
| `WS` | `/ws` | Real-time event stream |

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **ElevenLabs** - Voice AI (STT + TTS)
- **Google Gemini** - AI response generation
- **MongoDB** - NoSQL database
- **WebSockets** - Real-time communication

### Frontend
- **React 19** - UI framework
- **TailwindCSS** - Styling
- **Radix UI** - Accessible components
- **Axios** - HTTP client

## ğŸ”’ Environment Variables

### Backend (.env)
```
MONGO_URL=mongodb+srv://...
DB_NAME=voice_assistant_db
CORS_ORIGINS=*
```

### Frontend (.env)
```
REACT_APP_BACKEND_URL=http://localhost:8000
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [ElevenLabs](https://elevenlabs.io) - Voice AI platform
- [Google AI](https://ai.google.dev) - Gemini API
- [MongoDB](https://mongodb.com) - Database

---

<p align="center">
  Made with â¤ï¸ by <a href="https://github.com/vikas-6">Vikas Kumar</a>
</p>